{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import Preprocessing\n",
    "import imgaug.augmenters as iaa\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers, models\n",
    "from keras import applications\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Random Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_augmenter = iaa.Sequential([\n",
    "    # Horizontal Flip\n",
    "    iaa.Fliplr(0.5),\n",
    "\n",
    "    # Vertical Flip\n",
    "    iaa.Flipud(0.5),\n",
    "\n",
    "    # Multiply\n",
    "    iaa.Multiply((0.8, 1.2)),\n",
    "\n",
    "    # Linear Contrast\n",
    "    iaa.LinearContrast((0.6, 1.4)),\n",
    "\n",
    "    # Affine\n",
    "    iaa.Affine(translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "               rotate=(-30,30),\n",
    "               scale=(0.5, 1.5)),\n",
    "\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Images and Labels into two different arrays with Augmentation (imgaug) and Pre-processing (GrabCut + CLAHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Dataset/'\n",
    "dataset_path = os.listdir('Dataset')\n",
    "image_size = 224\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for label in dataset_path:\n",
    "    data_path = path + str(label)\n",
    "    filenames = [i for i in os.listdir(data_path)]\n",
    "\n",
    "    for filename in filenames:\n",
    "        img = cv2.imread(data_path + '/' + filename)\n",
    "\n",
    "        # Preprocessing the image\n",
    "        img = Preprocessing.preprocess(img)\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        \n",
    "        # image augmentation (horizontal and vertical flips)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "        cv2.imshow(\"Original\", img)\n",
    "\n",
    "        img = horizontal_flip(image=img)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "        cv2.imshow(\"Horizontal Flip\", img)\n",
    "\n",
    "        img = vertical_flip(image=img)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "        cv2.imshow(\"Horizontal & Vertical Flip\", img)\n",
    "\n",
    "        img = horizontal_flip(image=img)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "        cv2.imshow(\"Vertical Flip\", img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "images = np.array(images)\n",
    "images = images.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Dataframe for class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data=labels, columns=['Labels', 'Image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the Labels + Splitting the dataframe to train-test sets (80-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = dataframe['Labels'].values\n",
    "print(df_labels)\n",
    "\n",
    "df_labelEncoder = LabelEncoder()\n",
    "df_labels = df_labelEncoder.fit_transform(df_labels)\n",
    "print(df_labels)\n",
    "\n",
    "df_labels = df_labels.reshape(-1, 1)\n",
    "ct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "Y = ct.fit_transform(df_labels)\n",
    "\n",
    "images, Y = shuffle(images, Y, random_state=0)\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the EfficientNetB0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(dataset_path)\n",
    "IMG_SIZE = image_size\n",
    "size = (IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "outputs = applications.EfficientNetB0(include_top=True, weights=None, classes=NUM_CLASSES)(inputs)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model by 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_x, train_y, epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting an image from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img_path = \"Test1.JPG\" # Input Image\n",
    "\n",
    "pred_img = cv2.imread(pred_img_path)\n",
    "pred_img = Preprocessing.preprocess(pred_img)\n",
    "pred_img = cv2.resize(pred_img, (224, 224))\n",
    "\n",
    "test_img = np.expand_dims(pred_img, axis=0)\n",
    "\n",
    "prediction = model.predict(test_img) \n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'Model_SegmClahe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing model + Predicting an image / Obtaining test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import cv2\n",
    "import Preprocessing\n",
    "import numpy as np\n",
    "\n",
    "file_model = joblib.load('Full')\n",
    "# pred_img_path = \"OnlineHealthy.JPG\" # Input Image\n",
    "\n",
    "# pred_img = cv2.imread(pred_img_path)\n",
    "# pred_img = Preprocessing.preprocess(pred_img)\n",
    "# pred_img = cv2.resize(pred_img, (224, 224))\n",
    "\n",
    "# test_img = np.expand_dims(pred_img, axis=0)\n",
    "\n",
    "# prediction = file_model.predict(test_img) \n",
    "# prediction\n",
    "\n",
    "\n",
    "preds = file_model.evaluate(test_x, test_y)\n",
    "print(\"Loss = \" + str(preds[0]))\n",
    "print(\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"Train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(hist)\n",
    "\n",
    "preds = model.evaluate(test_x, test_y)\n",
    "print(\"Loss = \" + str(preds[0]))\n",
    "print(\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# predict probabilities for test set\n",
    "yhat_classes = file_model.predict(test_x, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "# yhat_classes = np.argmax(file_model.predict(test_x), axis=-1)\n",
    "# reduce to 1d array\n",
    "# yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    " \n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_y, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_y, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_y, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_y, yhat_classes)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
